# Single linear regression
```{r}
#| results: "asis"
#| echo: false

source("_common.R")
status("polishing")
```

## Overview

Single linear regression is an appropriate way to analyse data when:


-   You have two continuous variables
-   One of the variables is explanatory and the other is a response. That is, one variable, the $x$, "causes" the $y$. 
-   The explanatory variable has been chosen, set or manipulated and the other variable is the measured response. This is sometimes described as the $x$ being   ‚Äúsampled without error‚Äù
-   The response variable, $y$, is randomly sampled for each $x$ with a normal distribution and those normal distributions have the same variance.
-   The relationship between the variables is linear

Applying a single linear regression to data means putting a line of best fit through it. The intercept and the slope of the true population relationship is estimated from the sample you have. We test whether those two parameters differ significantly from zero. 


### Reporting

Reporting [the significance of effect, direction of effect, magnitude of effect](https://3mmarand.github.io/comp4biosci/what_statistical_model.html#reporting) for a single linear regression means making the following clear to the reader:


1. the significance of effect - whether the slope is significantly different from zero 

2. the direction of effect - whether the slope is positive or negative

3. the magnitude of effect - the slope itself

Figures should reflect what you have said in the statements. Ideally they should show both the raw data and the statistical model:

We will explore all of these ideas with an example.

## üé¨ Your turn!

If you want to code along you will need to start a new [RStudio project](workflow_rstudio.html#rstudio-projects), add a `data-raw` folder and open a new script. You will also need to load the **`tidyverse`** package [@tidyverse].


## Single linear regression


Three replicates water baths were set up at each of five temperatures (10, 11C, 12C, 13C, 14C). Ten Brine Shrimp (*Artemia salina*) were placed in each and their average respiration rate per water bath was measured (in arbitrary units). The data are in [shrimp.txt](data-raw/shrimp.txt).

### Import and explore

Import the data:

```{r}
shrimp <- read_table("data-raw/shrimp.txt")
```

```{r}
#| echo: false

knitr::kable(shrimp) %>%
  kableExtra::kable_styling() |> 
  kableExtra::scroll_box(height = "200px")
```

These data are in tidy format [@Wickham2014-nl] - all the respiration values are in one column with another column indicating the water bath temperature. There is only one water bath per row. This means they are well formatted for analysis and plotting.

In the first instance, it is sensible to create a rough plot of our data (See @fig-shrimp-rough). Plotting data early helps us in multiple ways:

-   it helps identify whether there missing or extreme values
-   it allows us to see if the relationship is roughly linear
-   it tells us whether any relationship positive or negative 

Scatter plots (`geom_point()`) are a good choice for exploratory plotting with data like these.

```{r}
#| label: fig-shrimp-rough
#| fig-cap: "A default scatter plot of the relationship between temperature and respiration rate in brine shrimp is enough for us to see that respiration rate seems to increase with temperature approximately linearly."

ggplot(data = shrimp,
       aes(x = temperature, y = respiration)) +
  geom_point()
```

The figure suggests that respiration rate increases with temperature and there are no particularly extreme values. We can also see that any relationship is roughly linear. 

### Do a regression with `lm()`

We can create a single linear regression model like this:

```{r}
mod <- lm(data = shrimp, respiration ~ temperature)
```

And examine the model with:

```{r}
summary(mod)
```
```{r}
#| echo: false

b0 <- mod$coefficients[1] |> round(2)
b1 <- mod$coefficients[2] |> round(2)
```


What do all these results mean?

The `Estimate` in the `Coefficients` table give:

-   the `(Intercept)` known as $\beta_0$,  which is the value of the *y* (the response) when the value of *x* (the explanatory) is zero. 

-   the slope labelled `temperature` known as $\beta_1$, which is the amount of *y* you add for each unit of *x*. `temperature` is positive so respiration rate increases with temperature

@fig-regression-lm-model shows the model and its parameters.

The *p*-values on each line are tests of whether that coefficient is different from zero. Thus it is:

`temperature  0.91850    0.09182  10.003 1.79e-07 ***`

that tells us the slope is significantly different from zero and thus there *is* a significant  relationship between temperature and respiration rate.

The *F* value and *p*-value in the last line are a test of whether the model as a whole explains a significant amount of variation in the response variable. For a regression, this is exactly equivalent to the test of the slope against zero and the two *p*-values will be the same.

```{r}
#| echo: false
#| label: fig-regression-lm-model
#| fig-cap: "In a linear model, the first estimate is the intercept and the second estimate is the 'slope'."
ggplot(data = shrimp, 
                aes(x = temperature, y = respiration)) +
  geom_point(colour = "black") +   
  geom_abline(intercept = b0,
              slope = b1,
              pal3[1], linetype = 2) +
  geom_smooth(method = "lm", 
              se = FALSE,
              colour = pal3[1]) +
  scale_x_continuous(expand = c(0,0),
                     limits = c(0, 15),
                      name = "Temperature (C)") +
  scale_y_continuous(expand = c(0,0), 
                     limits = c(-0, 20),
                     name = "Respiration (units)") +
  geom_segment(aes(x = 2,
                   xend = 0,
                   y = b0 + 6,
                   yend = b0),
               colour = pal3[2]) +
  annotate("text",
           x = 3, 
           y = b0 + 6.5,
           label = glue::glue("Intercept (Œ≤0) is { b0 }"), 
           colour = pal3[2],
           size = 4) +
  geom_segment(aes(x = 9,
                   xend = 9,
                   y = b0 + b1 * 8,
                   yend = b0 + b1 * 9),
               colour = pal3[3]) +
   geom_segment(aes(x = 8,
                   xend = 9,
                   y = b0 + b1 * 8,
                   yend = b0 + b1 * 8),
               colour = pal3[3]) +
  geom_segment(aes(x = 9,
                   xend = 12,
                   y = b0 + b1 * 8.5,
                   yend = b0 + 1.3),
               colour = pal3[2]) +
  annotate("text",
           x = 12, 
           y = b0 + 1,
           label = glue::glue("slope (Œ≤1) is { b1 }"), 
           colour = pal3[2],
           size = 4) +
  theme_classic()

```

### Check assumptions

Check the assumptions: All general linear models assume the "residuals" are normally distributed and have "homogeneity" of variance.

Our first check of these assumptions is to use common sense: respiration is a continuous variable and we would expect it to be normally distributed thus we would expect the residuals to be normally distributed

We then proceed by plotting residuals. The `plot()` function can be used to plot the residuals against the fitted values (See @fig-regression-plot1). This is a good way to check for homogeneity of variance. 

```{r}
#| label: fig-regression-plot1
#| fig-cap: "A plot of the residuals against the fitted values shows no obvious pattern as the points are roughly evenly distributed around the line. This is a good sign for the assumption of homogeneity of variance."

plot(mod, which = 1)
```

We can also use a histogram to check for normality (See @fig-regression-plot2).

```{r}
#| label: fig-regression-plot2
#| fig-cap: "A histogram of residuals is symetrical and seems consistent with a normal distribution. This is a good sign for the assumption of normally distributed residuals."
ggplot(mapping = aes(x = mod$residuals)) + 
  geom_histogram(bins = 5)
```

Finally, we can use the Shapiro-Wilk test to test for normality.
```{r}
shapiro.test(mod$residuals)
```

The p-value is greater than 0.05 so this test of the normality assumption is not significant. Note that "not significant" means not significantly different from a normal distribution. It does not mean definitely normally distributed.

Taken together, these results suggest that the assumptions of normality and homogeneity of variance are not violated.

### Report

The temperature explained a significant amount of the variation in respiration rate (ANOVA: *F* = 67; *d.f*. = 1, 13; *p* < 0.001). The regression line is: Respiration rate = `r b0` + `r b1` * temperature. See @fig-shrimp.

```{r}
#| label: fig-shrimp
#| fig-cap: "The effect of altering water bath temperature on the average respiration rate of brine shrimps."

ggplot(data = shrimp, 
                aes(x = temperature, y = respiration)) +
  geom_point(size = 2) +   
  geom_smooth(method = "lm", 
              se = FALSE,
              colour = "black") +
  scale_x_continuous(expand = c(0,0),
                     limits = c(0, 15.5),
                      name = "Temperature (C)") +
  scale_y_continuous(expand = c(0,0), 
                     limits = c(0, 20),
                     name = "Respiration (units)") +
  theme_classic()
```
