{
  "hash": "b08c78151bcbbce23f439ce6d8ced9cf",
  "result": {
    "engine": "knitr",
    "markdown": "# The logic of hyothesis testing {#sec-logic-hyopthesis-testing}\n\n\n::: {.callout-tip} \n## Complete\nYou are reading a live document. This page is compete but suggestions for improvements are welcome. Follow the link to 'Report an issue' to suggest improvements.\n:::\n\n## What is Hypothesis testing?\n\nHypothesis testing is a statistical method that helps us draw \nconclusions about a population based on a sample. Since we usually \ncanâ€™t measure every individual in a population, we take a smaller \nsample and analyze it.\n\nFor example, suppose we want to know if babies born to mothers in \npoverty have lower birth weights than the national average. Measuring\nthe birth weight of every baby in the country would be impossible, \nso we take a sample. However, even if poverty has no real effect, \nour sampleâ€™s average birth weight might be different from the national\naverage just by chance. Hypothesis testing helps us determine whether\nthis difference is real or just random variation.\n\n## Samples and populations\n\nBefore we dive deeper into hypothesis testing, letâ€™s clarify two \nkey terms:\n\n-   A population is the entire group we are interested in studying\n    (e.g., all babies in a country).\n-   A sample is a smaller group selected from the population \n    (e.g., a few hundred babies chosen for the study).\n\nWe use samples because studying an entire population is often \nimpractical. The challenge is making sure our sample accurately \nrepresents the population.\n\n## Logic of hypothesis testing\n\nThe logic behind hypothesis testing follows these general steps:\n\n1.  Formulating a \"Null Hypothesis\" denoted $H_0$. The null hypothesis\n    is what we expect to happen if nothing interesting is happening. It\n    states that there is no difference between groups or no relationship\n    between variables. In contrast, the \"Alternative Hypothesis\" ($H_1$)\n    states that there is a significant difference between groups or a\n    relationship between variables.\n2.  Designing an experiment and/or collecting data to test the null\n    hypothesis.\n3.  Finding the probability (the *p*-value) of getting our experimental\n    data, or data more extreme, if $H_0$ is true.\n4.  Deciding whether to reject or not reject the $H_0$ based on that\n    probability:\n    -   If $p â‰¤ 0.05$  we reject $H_0$\n    -   If $p > 0.05$  do not reject $H_0$\n\nIf the null hypothesis is rejected it means we have evidence that $H_0$\nis untrue and support for $H_1$. If the null hypothesis is not rejected,\nit means there is insufficient evidence to support the alternative\nhypothesis. \nIt is important to recognise that not rejecting the null hypothesis\ndoes not mean $H_0$ is definitely true. It just means just that $H_0$\ncannot be discounted. \n\nThere is a real state to $H_0$, that is, $H_0$ is either true or it is \nnot true. The statistical test has us decide whether to reject or\nnot reject $H_0$ based on the *p*-value. This means we can make mistakes\nwhen testing a hypothesis. These are called Type I and Type II errors.\n\n### Type I and type II errors\n\nType I and type II errors describe the cases when we make the wrong\ndecision about the null hypothesis. These errors are inherent in the\napproach rather than mistakes you can prevent.\n\n-   A type I error occurs when we reject a null hypothesis that is true.\n    This can be thought of as a false positive. It is a real error in\n    that we have a real difference or effect. Since we use a probability\n    of 0.05 to reject the null hypothesis, we will make a type I error\n    5% of the time.\n-   A type II error occurs when we do not reject a null hypothesis that\n    is false. This is a false negative. It is not a real error in the\n    sense that we only conclude we do not have enough evidence to reject\n    the null hypothesis.\n-   If we reject a null hypothesis that is false we have not made an\n    error.\n-   If we do not reject a null hypothesis that is true we have not made\n    an error.\n\n![Type I and Type II\nerrors.](images/type-1-2-errors.png){fig-alt=\"tabular representation of type I and II error. If we reject a true H0 we have made a type I error; if we do not reject a true H0 we have not made an error. If we do not reject a false H0 we have not made an error; if we do reject a false H0 we have made a type II error\"}\n\nWe can decrease our chance of making a type I error by reducing the the\n*p*-value required to reject the null hypothesis. However, this will\nincrease our chance of making a type II error. We can decrease our\nchance of making a type II error by collecting enough data. The amount\nof data needed will depend on the the size of the effect relative to the\nrandom variation in the data.\n\n## Sampling distribution of the mean\n\nThe sampling distribution of the mean is a fundamental concept in\nhypothesis testing and constructing confidence intervals. Parametric\ntests such as regression, two-sample tests and ANOVA (all applied with\n`lm()`) are based on the sampling distribution of the mean. It is a\ntheoretical distribution that describes the distribution of the sample\nmeans if an infinite number of samples were taken.\n\nThe key characteristics of the sampling distribution of the mean are:\n\n-   The mean of the sampling distribution of the mean is equal to the\n    population mean\n\n-   The standard deviation of the sampling distribution of the mean is\n    known the standard error of the mean and is always smaller than the\n    standard deviation of the values. There is a fixed relationship\n    between the standard deviation of a sample or population and the\n    standard error of the mean: $s.e. = \\frac{s.d.}{\\sqrt{n}}$\n\nðŸ’¡ Why does this matter? When we calculate a p-value, weâ€™re really \nasking: \"How likely is it to get a sample mean like ours (or more \nextreme) if $H_0$ is true. This is why understanding the sampling \ndistribution is so important - it helps us determine what results we \nshould expect by random chance.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![The sampling distribution of the means is a theoretical distribution that describes the distribution of the sample means if an infinite number of samples of size n were taken. The sampling distribution of the mean has a standard devation which is smaller than the population and is called the standard error.](logic-hyopthesis-testing_files/figure-html/fig-sample-dist-means-1.png){#fig-sample-dist-means width=576}\n:::\n:::\n\n\n### Example\n\nLet's work through this logic using an example.\n\nQuestion: National average birth weight is 3300 grams with an s.d. = 900\ngrams. Does maternal poverty influence birth weight?\n\n1.  Set up the null hypothesis. The null hypothesis is what we \n    expect to happen if nothing interesting is happening. In this case,\n    that there is no effect of maternal poverty on\n    birth weight, *i.e.*, the mean of a sample of babies born into \n    poverty is equal to the national average (@fig-null-example). This \n    is written as $H_0: \\bar{x} = 3300$. The alternative hypothesis \n    is that the sample mean is not equal to the national average. This \n    is written as $H_1: \\bar{x} \\neq 3300$.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Distribution of the population of birth weights has a mean of 3300 g and a standard deviation of 900. The null hypothesis is that the mean birth weight of babies born to women in poverty is the same as the national average of 3300 g.](logic-hyopthesis-testing_files/figure-html/fig-null-example-1.png){#fig-null-example width=576}\n:::\n:::\n\n\n2.  Design an experiment that generates data to test the null \n    hypothesis[^logic_hyopthesis_testing-1]. We take a sample \n    of $n = 12$ women who live in poverty and determine the mean birth \n    weight of their babies. We calculate $\\bar{x} = 3000 g$. This is \n    lower than the national average but might we get a sample like that\n    even if the null hypothesis is true?\n\n[^logic_hyopthesis_testing-1]: In fact this is an observational study\nrather than a real experimental study. This means we can potential\nconclude birth weight differs in the two groups but we cannot say\nmaternal poverty causes that difference.\n\n\n3.  Determine the probability (the *p*-value) of getting our\n    experimental data, or more extreme data, if $H_0$ is true.\n    (@fig-sample-dist-means-example)\n\n\n::: {.cell}\n::: {.cell-output-display}\n![The probability of getting a sample mean of 3000 or less is the area under the sampling distribution of the mean to the left of 3000.](logic-hyopthesis-testing_files/figure-html/fig-sample-dist-means-example-1.png){#fig-sample-dist-means-example width=576}\n:::\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![The probability of getting a sample mean of 3000 or more extreme is the area under the sampling distribution of the mean to the left of 3000 plus that to the right of 3600. This is because 3600 is as extreme (as far away from the mean) as 3000.](logic-hyopthesis-testing_files/figure-html/fig-sample-dist-means-example2-1.png){#fig-sample-dist-means-example2 width=576}\n:::\n:::\n\n\n4.  Decide whether to reject or not reject the $H_0$ based on that\n    probability. If the shaded area is less than 0.05 we reject the null\n    hypothesis and conclude there is a difference in the birth weights \n    between the two groups. If the shaded area is more than 0.05 we do \n    not reject the null hypothesis.\n",
    "supporting": [
      "logic-hyopthesis-testing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}