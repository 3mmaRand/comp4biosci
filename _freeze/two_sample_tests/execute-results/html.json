{
  "hash": "178b0dec279c197b67aa4de04e8bfd01",
  "result": {
    "engine": "knitr",
    "markdown": "# Two-Sample tests\n\n\n\n\n\n::: {.callout-tip} \n## Just needs proof reading\nYou are reading a work in progress. This page is compete but needs final proof reading.\n:::\n\n\n\n\n## Overview\n\nIn the last chapter, we explored single linear regression, a technique\nused when the explanatory variable is continuous. Now, we shift our\nfocus to cases where the explanatory variable is categorical with two\ngroups. For example, we may want to determine if there is a difference\nin mass between two subspecies of chaffinch or compare marks in two\nsubjects.\n\nTo conduct a two-sample test, we use either `lm()` or `wilcox.test()`,\ndepending on whether the assumptions of `lm()` are met. General linear\nmodels applied with `lm()` are parametric tests, meaning they rely on\nthe normal distribution's parameters (mean and standard deviation) to\ndetermine statistical significance. The null hypothesis typically\nconcerns the mean or the difference between means. For the *p*-values to\nbe valid, the assumptions must be satisfied.\n\nIf these assumptions are not met, we turn to non-parametric tests, which\nrely on the ranks of values rather than the actual values themselves.\nHere, the null hypothesis concerns the mean rank instead of the mean.\nWhile non-parametric tests are more flexible and applicable in a wider\nrange of scenarios, they tend to be less powerful, meaning they are less\nlikely to detect a true difference when one exists.\n\n### Independent vs. Paired Samples\n\nA crucial consideration when conducting tests is whether the values in\none group are independent of those in the other. Non-independence occurs\nwhen the two measures are linked in some wayâ€”for instance, if they come\nfrom the same individual, time, or location.\n\nFor example, when evaluating a treatment for high blood pressure, we\nmight measure blood pressure before and after treatment on the same\nindividuals. In this case, the before and after measurements are not\nindependent. If pairs of observations across groups share a common\nfactor that makes them more similar to each other than to other\nobservations, the samples are not independent.\n\nWe use different testing approaches for independent and non-independent\nsamples to account for this dependency.\n\n### *T*-tests\n\nA linear model with one explanatory variable with two groups is also\nknown as a **two-sample *t*-test** when the samples are independent and\nas a **paired-samples *t*-test** when they are not. R does have a\n`t.test()` function which allows you to fit a linear model with just two\ngroups. However, here we teach you to use and interpret the `lm()`\nfunction because it is more generalisable. You can use `lm()` when you\nhave three or more groups or additional explanatory variables. The\noutput of `lm()` is also in the same form as many other statistical\nfunctions in R. This means what you learn in performing *t*-tests with\n`lm()` will help you learn other methods more easily. However, it is\ndefinitely not wrong to use `t.test()` rather than `lm()` for two-group\nsituations - the procedures are identical and the *p*-values will be the\nsame.\n\n### Model assumptions\n\nThe assumptions of the general linear model are that the residuals are\nnormally distributed and have homogeneity of variance. A residual is the\ndifference between the predicted value and the observed value.\n\nIf we have a continuous response and a categorical explanatory variable\nwith two groups, we usually apply the general linear model with `lm()`\nand *then* check the assumptions, however, we can sometimes tell when a\nnon-parametric test would be more appropriate before that:\n\n-   Use common sense - the response should be continuous (or nearly\n    continuous, see [Ideas about data: Theory and\n    practice](ideas_about_data.html#theory-and-practice)). Consider\n    whether you would expect the response to be continuous.\n\n-   We expect decimal places and few repeated values.\n\nTo examine the assumptions after fitting the linear model, we plot the\nresiduals and test them against the normal distribution in the same way\nas we did for single linear regression.\n\n### Reporting\n\nIn reporting the result of two-sample test we give:\n\n1.  the significance of effect - whether there is there a difference\n    between the groups\n\n    -   parametric: whether there is there a difference between the\n        groups means\n    -   non-parametric: whether there is there a difference between the\n        group medians\n\n2.  the direction of effect - which of the means/medians is greater\n\n3.  the magnitude of effect - how big is the difference between the\n    means/medians\n\n    -   parametric: the means and standard errors for each group or the\n        mean difference for paired samples\n    -   non-parametric: the medians for each group or the median\n        difference for paired samples\n\nFigures should reflect what you have said in the statements. Ideally\nthey should show both the raw data and the statistical model:\n\n-   parametric: means and standard errors\n-   non-parametric: boxplots with medians and interquartile range\n\nWe will explore all of these ideas with some examples.\n\n## ðŸŽ¬ Your turn!\n\nIf you want to code along you will need to start a new [RStudio\nproject](workflow_rstudio.html#rstudio-projects), add a `data-raw`\nfolder and open a new script. You will also need to load the\n**`tidyverse`** package [@tidyverse].\n\n## Two independent samples, parametric\n\nA number of [subspecies of the common chaffinch, *Fringilla\ncoelebs*](https://en.wikipedia.org/wiki/Common_chaffinch), have been\ndescribed based principally on the differences in the pattern and colour\nof the adult male plumage [@suÃ¡rez2009]. Two of groups of these\nsubspecies are:\n\n-   the \"coelebs group\" (@fig-coelebs) that occurs in Europe and Asia\n-   the \"canariensis group\" (@fig-canariensis) that occurs on the Canary\n    Islands.\n\n::: {#fig-subspecies layout-ncol=\"2\"}\n![*F. c.\ncoelebs*](images/512px-Chaffinch_(Fringilla_coelebs).jpg){#fig-coelebs}\n\n![*F. c.\npalmae*](images/512px-Fringilla_coelebs_palmae_-_Los_Tilos.jpg){#fig-canariensis}\n\nAdult male *Fringilla coelebs* of the coelebs group on the left (Andreas\nTrepte, CC BY-SA 2.5 <https://creativecommons.org/licenses/by-sa/2.5>,\nvia Wikimedia Commons) and of the canariensis group on the right (H.\nZell, CC BY-SA 3.0 <https://creativecommons.org/licenses/by-sa/3.0>, via\nWikimedia Commons).\n:::\n\nThe data in [chaff.txt](data-raw/chaff.txt) give the masses of twenty\nindividuals from each subspecies. We want to know if the subspecies\ndiffer in mass. These groups are independent - there is no link between\nvalues in one group and any value in the other group. In this scenario\nour null hypothesis, $H_0$, is that there is no difference between the\ntwo subspecies in mass or that subspecies has no effect on mass. This is\nwritten as: $H_0: \\beta_1 = 0$.\n\n### Import and explore\n\nImport the data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchaff <- read_table(\"data-raw/chaff.txt\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<div style=\"border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:200px; \"><table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;position: sticky; top:0; background-color: #FFFFFF;\"> subspecies </th>\n   <th style=\"text-align:right;position: sticky; top:0; background-color: #FFFFFF;\"> mass </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 18.3 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 22.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 22.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 18.5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 22.2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 19.3 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 17.8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 20.2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 22.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 16.6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 20.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 18.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 22.6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 21.5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 21.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 19.9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 23.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 17.8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 19.5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> coelebs </td>\n   <td style=\"text-align:right;\"> 24.6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 22.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 20.6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 25.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 20.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 21.6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 17.0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 26.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 20.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 24.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 21.8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 23.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 24.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 21.0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 23.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 20.5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 21.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 21.5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 23.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 23.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> canariensis </td>\n   <td style=\"text-align:right;\"> 21.8 </td>\n  </tr>\n</tbody>\n</table></div>\n\n`````\n:::\n:::\n\n\n\n\nThese data are in tidy format [@Wickham2014-nl] - all the mass values\nare in one column with another column indicating the subspecies. This\nmeans they are well formatted for analysis and plotting.\n\nIn the first instance, it is always sensible to create a rough plot of\nour data. This is to give us an overview and help identify if there are\nany issues like missing or extreme values. It also gives us idea what we\nare expecting from the analysis which will make it easier for us to\nidentify if we make some mistake in applying that analysis.\n\nViolin plots (`geom_violin()`), box plots (`geom_boxplot()`, see\n@fig-chaff-rough) or scatter plots (`geom_point()`) all make good\nchoices for exploratory plotting and it does not matter which of these\nyou choose.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = chaff,\n       aes(x = subspecies, y = mass)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![The mass of two subspecies of chaffinch. A boxplot is a useful way to get an overview of the data and helps us identify any issues such as missing or extreme values. It also tells us what to expect from the analysis.](two_sample_tests_files/figure-html/fig-chaff-rough-1.png){#fig-chaff-rough width=576}\n:::\n:::\n\n\n\n\nR will order the groups alphabetically by default.\n\nThe figure suggests that the canariensis group is heavier than the\ncoelebs group.\n\nSummarising the data for each subspecies group is the next sensible\nstep. The most useful summary statistics are the means, standard\ndeviations, sample sizes and standard errors. I recommend the\n`group_by()` and `summarise()` approach:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchaff_summary <- chaff |> \n  group_by(subspecies) |> \n  summarise(mean = mean(mass),\n            std = sd(mass),\n            n = length(mass),\n            se = std/sqrt(n))\n```\n:::\n\n\n\n\nWe have save the results to `chaff_summary` so that we can use the means\nand standard errors in our plot later.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchaff_summary\n## # A tibble: 2 Ã— 5\n##   subspecies   mean   std     n    se\n##   <chr>       <dbl> <dbl> <int> <dbl>\n## 1 canariensis  22.3  2.15    20 0.481\n## 2 coelebs      20.5  2.14    20 0.478\n```\n:::\n\n\n\n\n### Apply `lm()`\n\nWe can create a two-sample model like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(data = chaff, mass ~ subspecies)\n```\n:::\n\n\n\n\nAnd examine the model with:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod)\n## \n## Call:\n## lm(formula = mass ~ subspecies, data = chaff)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -5.2750 -1.7000 -0.3775  1.6200  4.1250 \n## \n## Coefficients:\n##                   Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)        22.2750     0.4795  46.456   <2e-16 ***\n## subspeciescoelebs  -1.7950     0.6781  -2.647   0.0118 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.144 on 38 degrees of freedom\n## Multiple R-squared:  0.1557,\tAdjusted R-squared:  0.1335 \n## F-statistic: 7.007 on 1 and 38 DF,  p-value: 0.01175\n```\n:::\n\n\n\n\nThe Estimates in the Coefficients table give:\n\n-   `(Intercept)` known as $\\beta_0$. The mean of the canariensis group\n    (@fig-two-sample-lm-model). Just as the intercept is the value of\n    the *y* (the response) when the value of *x* (the explanatory) is\n    zero in a simple linear regression, this is the value of `mass` when\n    the `subspecies` is at its first level. The order of the levels is\n    alphabetical by default.\n\n-   `subspeciescoelebs`, known as $\\beta_1$, is what needs to be added\n    to the mean of the canariensis group to get the mean of the coelebs\n    group (@fig-two-sample-lm-model). Just as the slope is amount of *y*\n    that needs to be added for each unit of *x* in a simple linear\n    regression, this is the amount of `mass` that needs to be added when\n    the `subspecies` goes from its first level to its second level\n    (*i.e.*, one unit). The `subspeciescoelebs` estimate is negative so\n    the the coelebs group mean is lower than the canariensis group mean\n\nThe *p*-values on each line are tests of whether that coefficient is\ndifferent from zero. Thus it is:\n\n`subspeciescoelebs  -1.7950     0.6781  -2.647   0.0118 *`\n\nthat tells us the difference between the means is significant.\n\nThe *F* value and *p*-value in the last line are a test of whether the\nmodel as a whole explains a significant amount of variation in the\nresponse variable. For a two-sample test, just like a regression, this\nis exactly equivalent to the test of the slope against zero and the two\n*p*-values will be the same.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![In a two-sample linear model, the first estimate is the intercept which is the mean of the first group. The second estimate is the 'slope' which is what has to added to the intercept to get the second group mean. Note that y axis starts at 15 to create more space for the annotations.](two_sample_tests_files/figure-html/fig-two-sample-lm-model-1.png){#fig-two-sample-lm-model width=576}\n:::\n:::\n\n\n\n\n### Check assumptions\n\nCheck the assumptions: All general linear models assume the \"residuals\"\nare normally distributed and have \"homogeneity\" of variance.\n\nOur first check of these assumptions is to use common sense: mass is a\ncontinuous variable and we would expect it to be normally distributed\nthus we would also expect the residuals to be normally distributed.\n\nWe then plot the residuals. The `plot()` function can be used to plot\nthe residuals against the fitted values (See @fig-lm-plot1). This is a\ngood way to check for homogeneity of variance.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mod, which = 1)\n```\n\n::: {.cell-output-display}\n![A plot of the residuals against the fitted values shows the points are distributed similarly in each group. This is a good sign for the assumption of homogeneity of variance.](two_sample_tests_files/figure-html/fig-lm-plot1-1.png){#fig-lm-plot1 width=576}\n:::\n:::\n\n\n\n\nWe can also use a histogram to check for normality (See @fig-lm-plot2).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mapping = aes(x = mod$residuals)) + \n  geom_histogram(bins = 10)\n```\n\n::: {.cell-output-display}\n![A histogram of residuals is symetrical and seems consistent with a normal distribution. This is a good sign for the assumption of normally distributed residuals.](two_sample_tests_files/figure-html/fig-lm-plot2-1.png){#fig-lm-plot2 width=576}\n:::\n:::\n\n\n\n\nFinally, we can use the Shapiro-Wilk test to test for normality.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(mod$residuals)\n## \n## \tShapiro-Wilk normality test\n## \n## data:  mod$residuals\n## W = 0.98046, p-value = 0.7067\n```\n:::\n\n\n\n\nThe p-value is greater than 0.05 so this test of the normality\nassumption is not significant.\n\nTaken together, these results suggest that the assumptions of normality\nand homogeneity of variance are not violated.\n\n### Report\n\nCanariensis chaffinches ($\\bar{x} \\pm s.e$: 22.48 $\\pm$ 0.48) were\nsignificantly heavier than Coelebs (20.28 $\\pm$ 0.48 ) (*t* = 2.65;\n*d.f.* = 38; *p* = 0.012). See @fig-chaff.\n\n::: {#fig-chaff}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot() +\n  geom_point(data = chaff, aes(x = subspecies, y = mass),\n             position = position_jitter(width = 0.1, height = 0),\n             colour = \"gray50\") +\n  geom_errorbar(data = chaff_summary, \n                aes(x = subspecies, ymin = mean - se, ymax = mean + se),\n                width = 0.3) +\n  geom_errorbar(data = chaff_summary, \n                aes(x = subspecies, ymin = mean, ymax = mean),\n                width = 0.2) +\n  scale_y_continuous(name = \"Mass (g)\", \n                     limits = c(0, 30), \n                     expand = c(0, 0)) +\n  scale_x_discrete(name = \"Subspecies\", \n                   labels = c(\"Canariensis\", \"Coelebs\")) +\n  annotate(\"segment\", x = 1, xend = 2, \n           y = 28, yend = 28,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.5,  y = 29, \n           label = expression(italic(p)~\"= 0.012\")) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](two_sample_tests_files/figure-html/unnamed-chunk-13-1.png){width=576}\n:::\n:::\n\n\n\n\n**Canariensis chaffinches are heavier than Coelebs chaffinches**. The\nmean mass of 20 randomly sampled males from each subspecies was\ndetermined. Error bars are $\\pm$ 1 standard error. Canariensis\nchaffinches were significantly heavier than Coelebs (*t* = 2.65; *d.f.*\n= 38; *p* = 0.012). Data analysis was conducted in R [@R-core] with\ntidyverse packages [@tidyverse].\n:::\n\n## Two independent samples, non-parametric\n\nThe non-parametric equivalent of the linear model with two independent\nsamples is the \"Wilcoxon rank sum test\" [@wilcoxon1945]. It is commonly\nalso known as the Mann-Whitney or Wilcoxonâ€“Mannâ€“Whitney.\n\nThe general question you have about your data - are these two groups\ndifferent - is the same, but one of more of the following is true:\n\n-   the response variable is not continuous\n-   the residuals are not normally distributed\n-   the sample size is too small to tell if they are normally\n    distributed.\n-   the variance is not homogeneous\n\nThe test is a applied in R with the `wilcox.test()` function.\n\nThe data in [arabidopsis.txt](data-raw/arabidopsis.txt) give the number\nof leaves on eight wildtype and eight mutant *Arabidopsis thaliana*\nplants. We want to know if the two types of plants have differing\nnumbers of leaves. These are counts, so they are not continuous and the\nsample sizes are quite small. A non-parametric test is a safer option.\nIn this scenario our null hypothesis, $H_0$, is that there is no\ndifference between the two types of plant in the number of leaves.\n\n### Import and explore\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\narabidopsis <- read_table(\"data-raw/arabidopsis.txt\")\n```\n:::\n\n\n\n\nThese data are in tidy format [@Wickham2014-nl] - the numbers of leaves\nare in one column with another column indicating whether the observation\ncomes from a wildtype or mutant *Arabidopsis*. This means they are well\nformatted for analysis and plotting.\n\nCreate a quick plot of the data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = arabidopsis, \n       aes(x = type, y = leaves)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![The number of leaves on mutant and wildtype plants. A boxplot is a useful way to get an overview of the data and helps us identify any issues such as missing or extreme values. It also tells us what to expect from the analysis.](two_sample_tests_files/figure-html/fig-arabid-rough-1.png){#fig-arabid-rough width=576}\n:::\n:::\n\n\n\n\nOur rough plot shows that the mutant plants have fewer leaves than the\nwildtype plants.\n\nSummarising the data using the median and interquartile range is more\naligned to the type of data and the type of analysis than using means\nand standard deviations:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\narabidopsis_summary <- arabidopsis |> \n  group_by(type) |> \n  summarise(median = median(leaves),\n            interquartile  = IQR(leaves),\n            n = length(leaves))\n```\n:::\n\n\n\n\nView the results:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\narabidopsis_summary\n## # A tibble: 2 Ã— 4\n##   type   median interquartile     n\n##   <chr>   <dbl>         <dbl> <int>\n## 1 mutant    5             2.5     8\n## 2 wild      8.5           1.5     8\n```\n:::\n\n\n\n\n### Apply `wilcox.test()`\n\nWe pass the dataframe and variables to `wilcox.test()` in the same way\nas we did for `lm()`. We give the data argument and a \"formula\" which\nsays `leaves ~ type` meaning \"explain leaves by type\".\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(data = arabidopsis, leaves ~ type)\n## \n## \tWilcoxon rank sum test with continuity correction\n## \n## data:  leaves by type\n## W = 5, p-value = 0.005051\n## alternative hypothesis: true location shift is not equal to 0\n```\n:::\n\n\n\n\nThe warning message \"Warning: cannot compute exact p-value with ties\" is\nnot something to worry about too much. It is a warning rather than an\nindication that your results are incorrect. It means the *p* -value is\nbased on an approximation rather than being exact because there are ties\n(some values are the same).\n\nThe result of the test is given on this line:\n`W = 5, p-value = 0.005051`. `W` is the test statistic. The *p*-value is\nless than 0.05 meaning there is a significant difference in the number\nof leaves on wildtype and mutant plants.\n\n### Report\n\nThere are significantly more leaves on wildtype (median = 8.5) than\nmutant (median = 5) plants (Wilcoxon rank sum test: *W* = 5, $n_1$ = 8,\n$n_2$ = 8, *p* = 0.005). See @fig-arabid.\n\n::: {#fig-arabid}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(data = arabidopsis, \n       aes(x = type, y = leaves)) +\n  geom_boxplot() +\n  scale_y_continuous(name = \"Number of leaves\", \n                     limits = c(0, 12), \n                     expand = c(0, 0)) +\n  scale_x_discrete(name = \"\", \n                   labels = c(\"Mutatnt\", \"Wildtype\")) +\n  annotate(\"segment\", x = 1, xend = 2, \n           y = 10.5, yend = 10.5,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.5,  y = 11, \n           label = expression(italic(p)~\"= 0.005\")) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](two_sample_tests_files/figure-html/unnamed-chunk-19-1.png){width=576}\n:::\n:::\n\n\n\n\n**Mutant *Arabidopsis thaliana* have fewer leaves**. There are\nsignificantly more leaves on wildtype than mutant plants (Wilcoxon rank\nsum test: *W* = 5, $n_1$ = 8, $n_2$ = 8, *p* = 0.005). The heavy lines\nindicate the median of leaves, boxes indicate the interquartile range\nand whiskers the range. Data analysis was conducted in R [@R-core] with\ntidyverse packages [@tidyverse].\n:::\n\n## Two paired-samples, parametric\n\nThe data in [marks.csv](data-raw/marks.csv) give the marks for ten\nstudents in two subjects: Data Analysis and Biology. These data are\npaired because we have two marks from one student so that a mark in one\ngroup has a closer relationship with one of the marks in the other group\nthan with any of the other values. We want to know if students do\nequally well in both subjects. In this scenario our null hypothesis,\n$H_0$, is that there is no difference between the Data Analysis and\nBiology marks for a student.\n\n### Import and explore\n\nImport the data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks <- read_csv(\"data-raw/marks.csv\")\n```\n:::\n\n\n\n\nSince these data are paired, it makes sense to highlight how the marks\ndiffer for each student. One way of doing that is to draw a line linking\ntheir marks in each subject. This is known as a spaghetti plot. We can\nuse two geoms: `geom_point()` and `geom_line()`. To join a student's\nmarks, we need to set the `group` aesthetic to\n`student`.[^two_sample_tests-1]\n\n[^two_sample_tests-1]: You might like to try removing\n    `aes(group = student)` to see what ggplot does when the lines are\n    *not* grouped by student.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = marks, aes(x = subject, y = mark)) +\n  geom_point() +\n  geom_line(aes(group = student))\n```\n\n::: {.cell-output-display}\n![](two_sample_tests_files/figure-html/unnamed-chunk-21-1.png){width=576}\n:::\n:::\n\n\n\n\nSummarise the data so that we can use the means in plots later:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks_summary <- marks |>\n  group_by(subject) |>\n  summarise(mean = mean(mark))\n```\n:::\n\n\n\n\nA paired test requires us to into account the variation between\nstudents.\n\n### Apply `lm()`\n\nWe can create a paired-sample model with the `lm()`\nfunction[^two_sample_tests-2] like this:\n\n[^two_sample_tests-2]: This is not the only way to apply a paired test.\n    When there are only two groups and no other explanatory variables,\n    we can use `t.test(data = marks, mark ~ subject, paired = TRUE)`. A\n    more general method that works when you have two or more\n    non-independent values (e.g., more than two subjects) or additional\n    explanatory variables is to create a \"linear mixed model\" with\n    `lmer()`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(mark ~ subject + factor(student), data = marks)\n```\n:::\n\n\n\n\n-   `mark` is the dependent variable (response).\n-   `subject` is the independent variable (explanatory factor).\n-   `factor(student)` accounts for the pairing by treating student as\n    another explanatory variable. We have used factor because the values\n    in students are the numbers 1 to 10 and we want `student` to be\n    treated as a category not a number\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod)\n## \n## Call:\n## lm(formula = mark ~ subject + factor(student), data = marks)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n##   -6.5   -3.5    0.0    3.5    6.5 \n## \n## Coefficients:\n##                     Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)           89.500      4.697  19.055 1.39e-08 ***\n## subjectDataAnalysis    7.000      2.832   2.471 0.035486 *  \n## factor(student)2     -39.500      6.333  -6.237 0.000152 ***\n## factor(student)3     -26.500      6.333  -4.184 0.002361 ** \n## factor(student)4     -25.500      6.333  -4.026 0.002990 ** \n## factor(student)5     -16.000      6.333  -2.526 0.032431 *  \n## factor(student)6     -54.000      6.333  -8.526 1.33e-05 ***\n## factor(student)7      -9.000      6.333  -1.421 0.189010    \n## factor(student)8     -27.000      6.333  -4.263 0.002101 ** \n## factor(student)9     -44.000      6.333  -6.947 6.70e-05 ***\n## factor(student)10     -1.500      6.333  -0.237 0.818082    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.333 on 9 degrees of freedom\n## Multiple R-squared:  0.9441,\tAdjusted R-squared:  0.8821 \n## F-statistic: 15.21 on 10 and 9 DF,  p-value: 0.0001814\n```\n:::\n\n\n\n\nThe coefficient for `(Intercept)` gives the mean Biology mark and that\nfor `subjectDataAnalysis` is amount that the Data Analysis mark are\nabove Biology marks in general. The *p*-value tests whether this\ndifference is significantly different from zero. The rest of the output\nconsiders how students differ. You can ignore this here.\n\nIf you find this a bit overwhelming to read you can use the `anova()`\nfunction on the model object to get a simpler output:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod)\n## Analysis of Variance Table\n## \n## Response: mark\n##                 Df Sum Sq Mean Sq F value   Pr(>F)    \n## subject          1  245.0  245.00   6.108 0.035486 *  \n## factor(student)  9 5856.2  650.69  16.222 0.000153 ***\n## Residuals        9  361.0   40.11                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n\n\nYou will notice that the *p*-value for subject is the same. The test\nstatistic, $F$ has a value of \n6.11 \nand degrees of freedom of \n1 \nand\n9.\nThis would be written as $F = $\n6.11 ; \n$d.f.= $\n1, 9;\n$p = $\n0.035 .\n\n### Check assumptions\n\nWe might expect marks to be normally distributed. However, this is a\nvery small sample, and choosing a non-parametric test instead would be\nreasonable. However, we will continue with this example to demonstrate\nhow to interpret and report on the result of a parametric paired-samples\ntest (paired-samples *t*-test).\n\nA plot the residuals against the fitted values (`plot(mod, which = 1)`)\nis not useful for a paired test. The normality of the residuals should\nbe checked.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mapping = aes(x = mod$residuals)) +\n  geom_histogram(bins = 3)\n```\n\n::: {.cell-output-display}\n![](two_sample_tests_files/figure-html/unnamed-chunk-26-1.png){width=576}\n:::\n:::\n\n\n\n\nWe only have 10 values, so the distribution is never going to look\nsmooth. We can't draw strong conclusions from this, but we do at least\nhave a peak at 0. Similarly, a normality test is likely to be\nnon-significant because of the small sample size, meaning the test is\nnot very powerful. This means a non-significant result is not strong\nevidence of the residuals following a normal distribution:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(mod$residuals)\n## \n## \tShapiro-Wilk normality test\n## \n## data:  mod$residuals\n## W = 0.92894, p-value = 0.1473\n```\n:::\n\n\n\n\n### Report\n\nIndividual students score significantly higher in Data Analysis than in\nBiology (*t* = 2.47; *d.f.* = 9; *p* = 0.0355) with an average\ndifference of 7%. See @fig-marks\n\n::: {#fig-marks}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(data = marks, aes(x = subject, y = mark)) +\n  geom_point(pch = 1, size = 3) +\n  geom_line(aes(group = student), linetype = 3) +\n  geom_point(data = marks_summary,\n             aes(x = subject, y = mean),\n             size = 3) +\n  scale_x_discrete(name = \"\") +\n  scale_y_continuous(name = \"Mark\",\n                     expand = c(0, 0),\n                     limits = c(0, 110)) +\n  annotate(\"segment\", x = 1, xend = 2,\n           y = 105, yend = 105,\n           colour = \"black\") +\n  annotate(\"text\", x = 1.5,  y = 108,\n           label = expression(italic(p)~\"= 0.0355\")) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](two_sample_tests_files/figure-html/unnamed-chunk-28-1.png){width=576}\n:::\n:::\n\n\n\n\n**Students score higher in Data Analysis than in Biology**. Open circles\nindicate an individual student's marks in each subject with dashed lines\njoining their marks in each subject. The filled circles indicate the\nmean mark for each subject. Individual students score significantly\nhigher in Data Analysis than in Biology (*t* = 2.47; *d.f.* = 9; *p* =\n0.0355) with an average difference of 7%. Data analysis was conducted in\nR [@R-core] with tidyverse packages [@tidyverse].\n:::\n\n## Two paired-samples, non-parametric\n\nWe have the marks for just 10 students. This sample is too small for us\nto judge whether the marks are normally distributed. We will use a\nnon-parametric test instead. The \"Wilcoxon signed-rank\" test is the\nnon-parametric equivalent of the paired-samples *t*-test. This is often\nreferred to as the paired-sample Wilcoxon test, or just the Wilcoxon\ntest.\n\nThe test is also applied in R with the `wilcox.test()` function but we\nadd the `paired = TRUE` argument. We also have to give the two datasets\nrather than using the \"formula method\" of `mark ~ subject`. This means\nit is useful to pivot the data to \"wide\" format.\n\n### Pivot wider\n\nCreate a new dataframe marks_wide from marks:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks_wide <- marks |> \n  pivot_wider(values_from = mark, \n              names_from = subject, \n              id_cols = student)\n```\n:::\n\n\n\n\n-   `values_from = mark`: Uses the `mark` column as values in the wide\n    format.\n-   `names_from = subject`: Creates new columns based on unique values\n    in `subject`\n-   `id_cols = student`: Keeps `student` as the identifier (*i.e.*, each\n    row represents a student).\n\n### Apply `wilcox.test()`\n\nTo apply a paired test with `wilcox.test()` we need to use the wide\nformat data (untidy) and add the `paired = TRUE` argument:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(marks_wide$Biology, marks_wide$DataAnalysis, paired = TRUE)\n## \n## \tWilcoxon signed rank test with continuity correction\n## \n## data:  marks_wide$Biology and marks_wide$DataAnalysis\n## V = 6.5, p-value = 0.03641\n## alternative hypothesis: true location shift is not equal to 0\n```\n:::\n\n\n\n\n### Report\n\nIndividual students score significantly higher in Data Analysis than in\nBiology (Wilcoxon signed rank test: *V* = 6.5; $n$ = 10; *p* = 0.036).\n\n## Summary\n\n1.  A linear model with one explanatory variable with two groups and one\n    continuous response is \"a two-sample test\".\n\n2.  If pairs of observations in the groups have something in common that\n    make them more similar to each other, than to other observations,\n    then those observations are not independent. A **paired-samples\n    test** is used when the observations are not independent.\n\n3.  A linear model with one explanatory variable with two groups and one\n    continuous response is also known as a **two-sample *t*-test** when\n    the samples are independent and as a **paired-samples *t*-test**\n    when they are not\n\n4.  We can use `lm()` to do two-sample and paired sample tests. We can\n    also use `t.test()` for these but using `lm()` helps us understand\n    tests with more groups and/or more variables where we will have to\n    use `lm()`. The output of `lm()` is also more typical of the output\n    of statistical functions in R.\n\n5.  We estimate the **coefficients** (also called the **parameters**) of\n    the model. For a two-sample test these are the mean of the first\n    group, $\\beta_0$ (which might also be called the intercept) and the\n    difference between the means of the first and second groups,\n    $\\beta_1$ (which might also be called the slope). For a\n    paired-sample test there is just one parameter, the mean difference\n    between pairs of values, $\\beta_0$ (which might also be called the\n    intercept). We test whether the parameters differ significantly from\n    zero\n\n6.  We can use `lm()` to a linear regression.\n\n7.  In the output of `lm()` the coefficients are listed in a table in\n    the Estimates column. The *p*-value for each coefficient is in the\n    test of whether it differs from zero. At the bottom of the output\n    there is a test of the model *overall*. In this case, this is\n    exactly the same as the test of the $\\beta_1$ and the p-values are\n    identical. The R-squared value is the proportion of the variance in\n    the response variable that is explained by the model.\n\n8.  The assumptions of the general linear model are that the residuals\n    are normally distributed and have homogeneity of variance. A\n    residual is the difference between the predicted value and the\n    observed value.\n\n9.  We examine a histogram of the residuals and use the Shapiro-Wilk\n    normality test to check the normality assumption. We check the\n    variance of the residuals is the same for all fitted values with a\n    residuals vs fitted plot.\n\n10. If the assumptions are not met, we can use alternatives known as\n    non-parametric tests. These are applied with `wilcox.test()` in R.\n\n11. When reporting the results of a test we give the significance,\n    direction and size of the effect. Our figures and the values we give\n    should reflect the type of test we have used. We use means and\n    standard errors for parametric tests and medians and interquartile\n    ranges for non-parametric tests. We also give the test statistic,\n    the degrees of freedom (parametric) or sample size (non-parametric)\n    and the p-value. We annotate our figures with the p-value, making\n    clear which comparison it applies to.\n",
    "supporting": [
      "two_sample_tests_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}